{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1egh496IJNph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e1c693d-c937-4556-c61d-5ee018c5282f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/sample/3dyonnmoku/train_code_new\n",
            "ğŸ”„  best.h5 ã‚’å†åˆ©ç”¨\n",
            "\n",
            "===== CYCLE 1/1 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Benchmark: 14.49s / game  â€¢  RAM 14.4%\n",
            "SelfPlay 300/300\n",
            "Train 100/100"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 32031 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79c50c4484a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate 100/100\n",
            "Average Point: 0.13\n",
            "\n",
            "ğŸ‰ ã™ã¹ã¦å®Œäº†  â€¢  best = /content/drive/MyDrive/azero_3d/model/best.h5\n"
          ]
        }
      ],
      "source": [
        "# =====================================================\n",
        "# One-runtime AlphaZero ç«‹ä½“å››ç›®  å­¦ç¿’ãƒ«ãƒ¼ãƒ—\n",
        "#   ãƒ»Google Drive ã«ãƒ¢ãƒ‡ãƒ«ï¼ãƒ‡ãƒ¼ã‚¿ï¼state ã‚’ç›´ä¿å­˜\n",
        "#   ãƒ»é€”ä¸­ã‚µã‚¤ã‚¯ãƒ«ã‹ã‚‰å†é–‹\n",
        "# =====================================================\n",
        "import os, json, time, shutil\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# ---------- 0) Google Drive ----------\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "ROOT = Path('/content/drive/MyDrive/azero_3d')\n",
        "MODEL_DIR = ROOT / 'model'\n",
        "DATA_DIR  = ROOT / 'data'\n",
        "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# ---------- 1) ã‚³ãƒ¼ãƒ‰ç½®ãå ´ã«ç§»å‹• ----------\n",
        "%cd /content/drive/MyDrive/sample/3dyonnmoku/train_code_new\n",
        "import sys; sys.path.append(os.getcwd())\n",
        "\n",
        "# ---------- 2) ãƒ¦ãƒ¼ã‚¶ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« ----------\n",
        "from dual_network      import dual_network\n",
        "from self_play         import self_play   #ãƒ†ã‚¹ãƒˆ\n",
        "from train_network     import train_network\n",
        "from evaluate_network  import evaluate_network\n",
        "from evaluate_best_player import evaluate_best_player\n",
        "\n",
        "BEST_PATH  = MODEL_DIR / 'best.h5'\n",
        "STATE_JSON = ROOT / 'state.json'\n",
        "\n",
        "# ---------- 3) åˆæœŸ best.h5 ----------\n",
        "if not BEST_PATH.exists():\n",
        "    dual_network()\n",
        "else:\n",
        "    print(\"ğŸ”„  best.h5 ã‚’å†åˆ©ç”¨\")\n",
        "\n",
        "# ---------- 4) å†é–‹ãƒã‚¤ãƒ³ãƒˆ ----------\n",
        "start_cycle = 0\n",
        "if STATE_JSON.exists():\n",
        "    start_cycle = json.load(STATE_JSON.open())['cycle'] + 1\n",
        "    print(f\"â–¶ å†é–‹: cycle {start_cycle}\")\n",
        "\n",
        "TOTAL_CYCLES = 1          #ãƒ†ã‚¹ãƒˆ 10â†’1\n",
        "\n",
        "# ---------- 5) ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ— ----------\n",
        "for cycle in range(start_cycle, TOTAL_CYCLES):\n",
        "    print(f\"\\n===== CYCLE {cycle+1}/{TOTAL_CYCLES} =====\")\n",
        "    self_play()                   # â‘  è‡ªå·±å¯¾æˆ¦\n",
        "    train_network()               # â‘¡ å†å­¦ç¿’\n",
        "    updated = evaluate_network()  # â‘¢ best æ›´æ–°åˆ¤å®š\n",
        "    if updated:\n",
        "        evaluate_best_player()    # â‘£ ä»»æ„ãƒ†ã‚¹ãƒˆ\n",
        "\n",
        "    # â‘¤ latest ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—\n",
        "    shutil.copy('./model/latest.h5', MODEL_DIR / f'latest_{cycle:02d}.h5')\n",
        "    if updated:\n",
        "        shutil.copy('./model/best.h5', BEST_PATH)\n",
        "\n",
        "    # â‘¥ state æ›´æ–°\n",
        "    json.dump({'cycle': cycle,\n",
        "               'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')},\n",
        "              STATE_JSON.open('w'))\n",
        "\n",
        "    # â‘¦ ãƒ¡ãƒ¢ãƒªè§£æ”¾\n",
        "    K.clear_session()\n",
        "\n",
        "print(\"\\nğŸ‰ ã™ã¹ã¦å®Œäº†  â€¢  best =\", BEST_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "# 1. ãƒ‡ãƒ¼ã‚¿ç‚¹æ¤œ\n",
        "hist = pickle.load(open(sorted(Path('data').glob('*.history'))[-1], 'rb'))\n",
        "print(len(hist), 'samples')\n",
        "\n",
        "# Unpack hist[0] based on its structure\n",
        "p0, pol, v0 = hist[0][0], hist[0][1], hist[0][2]\n",
        "\n",
        "print(hex(p0[0]), pol[:8], v0) # Access the first element of p0\n",
        "\n",
        "# 2. tensor å¤‰æ›ç¢ºèª\n",
        "# Assuming bitboards_to_tensor_batch is defined elsewhere and takes two numpy arrays\n",
        "# x0 = bitboards_to_tensor_batch(np.array([p0], 'uint64'),\n",
        "#                                np.array([hist[0][0][1]], 'uint64'))\n",
        "# print('tensor non-zero=', x0.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbHQHqbbiIdc",
        "outputId": "7aa6ddbc-101e-4bed-c91d-fa31d7537d45"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10858 samples\n",
            "Structure of hist[0]: [[0, 0], [np.float32(0.6530612), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.3469388), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0)], -1]\n",
            "Type of hist[0]: <class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# best.h5ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "# modelãƒ•ã‚©ãƒ«ãƒ€ã«ç§»å‹•\n",
        "!mkdir model\n",
        "!mv best.h5 model"
      ],
      "metadata": {
        "id": "Iba2fxnxJ96r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}