# -*- coding: utf-8 -*-
"""dual_network.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uA-qgc4l_9ZRXxGakyrV_Yj7dO1j_1m8
"""

# ====================
# Dual Network 4×4×4 立体四目   ハイパーパラメータ一括管理版
# ====================
from __future__ import annotations
from tensorflow.keras.layers import (Input, Conv2D, BatchNormalization, Activation,
                                     Add, GlobalAveragePooling2D, Dense)
from tensorflow.keras.models import Model
from tensorflow.keras.regularizers import l2
from tensorflow.keras import backend as K
import os
import numpy as np

# --------------------
# ハイパーパラメータ
# --------------------
HP = dict(
    filters       = 96,
    residual_num  = 12,
    board_size    = 4,
    l2_reg        = 5e-4,
    model_path    = './model/best.h5'
)

# 盤サイズとチャンネル数はここで一元管理
SIZE  = HP['board_size']
CHAN  = SIZE * 2                # 自分 + 相手
DN_INPUT_SHAPE = (SIZE, SIZE, CHAN)
DN_OUTPUT_SIZE = SIZE ** 2      # 列数 (= SIZE×SIZE)



def state_to_tensor(state: 'State') -> np.ndarray:
    t = np.zeros(DN_INPUT_SHAPE, dtype=np.float32)

    mine  = np.unpackbits(np.array([state.pieces], dtype=np.uint64).view(np.uint8),
                          bitorder='little').astype(bool).reshape(SIZE, SIZE, SIZE)
    yours = np.unpackbits(np.array([state.enemy_pieces], dtype=np.uint64).view(np.uint8),
                          bitorder='little').astype(bool).reshape(SIZE, SIZE, SIZE)

    t[..., :SIZE] = mine.transpose(1, 2, 0)   # 自分
    t[..., SIZE:] = yours.transpose(1, 2, 0)  # 相手
    return t

# --------------------
# レイヤーヘルパ
# --------------------
def conv(filters):
    """3×3 Convolution + He init + L2"""
    return Conv2D(filters, 3, padding='same', use_bias=False,
                  kernel_initializer='he_normal',
                  kernel_regularizer=l2(HP['l2_reg']))

def residual_block():
    """2-layer Residual Block with BN-ReLU-Conv"""
    def f(x):
        sc = x
        x = conv(HP['filters'])(x)
        x = BatchNormalization()(x)
        x = Activation('relu')(x)

        x = conv(HP['filters'])(x)
        x = BatchNormalization()(x)

        x = Add()([x, sc])
        x = Activation('relu')(x)
        return x
    return f

# --------------------
# デュアルネットワーク作成
# --------------------
def dual_network(force_rebuild=False):
    """
    best.h5 が無い場合 or force_rebuild=True で新規作成して保存
    """
    if not force_rebuild and os.path.exists(HP['model_path']):
        return

    # 入力
    inp = Input(shape=DN_INPUT_SHAPE)

    # 先頭 Conv
    x = conv(HP['filters'])(inp)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)

    # 残差ブロック
    for _ in range(HP['residual_num']):
        x = residual_block()(x)

    # Global Average Pooling
    x = GlobalAveragePooling2D()(x)

    # --- Policy head ---
    p = Dense(DN_OUTPUT_SIZE, kernel_regularizer=l2(HP['l2_reg']),
              activation='softmax', name='pi')(x)

    # --- Value head ---
    v = Dense(1, kernel_regularizer=l2(HP['l2_reg']))(x)
    v = Activation('tanh', name='v')(v)

    # モデル
    model = Model(inputs=inp, outputs=[p, v])

    # 保存
    os.makedirs(os.path.dirname(HP['model_path']), exist_ok=True)
    model.save(HP['model_path'])

    # メモリ解放
    K.clear_session()
    del model


# --------------------
# 動作確認
# --------------------
if __name__ == '__main__':
    dual_network(force_rebuild=True)      # ←既存モデル上書きしたくなければ False
    print('Dual network saved to', HP['model_path'])